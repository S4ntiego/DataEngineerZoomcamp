# Cleaning both datasets to match each other, union them into one dataframe

Open up new Jupyter Notebook called 06_spark_sql

```python 06_spark_sql
import pyspark
from pyspark.sql import types
from pyspark.sql import SparkSession
from pyspark.sql import functions as F

spark = SparkSession.builder \
    .master("local[*]") \
    .appName("test") \
    .getOrCreate()

df_green = spark.read.parquet('data/pq/green/*/*')
df_yellow = spark.read.parquet('data/pq/yellow/*/*')
# check the intersection of columns between df_green and yellow, rename datetime columns to match each other
set(df_green.columns) & set(df_yellow.columns)
df_green = df_green \
    .withColumnRenamed('lpep_pickup_datetime', 'pickup_datetime') \
    .withColumnRenamed('lpep_dropoff_datetime', 'dropoff_datetime')
df_yellow = df_yellow \
    .withColumnRenamed('tpep_pickup_datetime', 'pickup_datetime') \
    .withColumnRenamed('tpep_dropoff_datetime', 'dropoff_datetime')
# to preserve the column order
common_columns = []
yellow_columns = set(df_yellow.columns)
for column in df_green.columns:
    if column in yellow_columns:
        common_columns.append(column)
# assign common columns of both taxi data from green dataset and add green service type column 
df_green_select = df_green. \
    select(common_columns) \
    .withColumn('service_type', F.lit('green'))
# assign common columns of both taxi data from yellow dataset and add yellow service type column 
df_yellow_select = df_yellow. \
    select(common_columns) \
    .withColumn('service_type', F.lit('yellow'))
# union both datasets
df_trips_data = df_green_select.unionAll(df_yellow_select)
# count records by taxi type
df_trips_data.groupBy('service_type').count().show()
```

# Using SQL with Spark

```python 06_spark_sql
# create a temp table from the data frame and call it 'trips_data'
df_trips_data.registerTempTable('trips_data')
# assign sql query to df_result
df_result = spark.sql("""
SELECT 
    -- Reveneue grouping 
    PULocationID AS revenue_zone,
    date_trunc('month', pickup_datetime) AS revenue_month, 
    service_type, 

    -- Revenue calculation 
    SUM(fare_amount) AS revenue_monthly_fare,
    SUM(extra) AS revenue_monthly_extra,
    SUM(mta_tax) AS revenue_monthly_mta_tax,
    SUM(tip_amount) AS revenue_monthly_tip_amount,
    SUM(tolls_amount) AS revenue_monthly_tolls_amount,
    SUM(improvement_surcharge) AS revenue_monthly_improvement_surcharge,
    SUM(total_amount) AS revenue_monthly_total_amount,
    SUM(congestion_surcharge) AS revenue_monthly_congestion_surcharge,

    -- Additional calculations
    AVG(passenger_count) AS avg_montly_passenger_count,
    AVG(trip_distance) AS avg_montly_trip_distance
FROM
    trips_data
GROUP BY
    1, 2, 3
""")
# use coalesce to make one big parquet file (contrary to repartitioning) and save result as parquet file
df_result.coalesce(1).write.parquet('data/report/revenue', mode="overwrite")
```


